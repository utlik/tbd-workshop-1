{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3nz_krXOcakE"
      },
      "outputs": [],
      "source": [
        "pip install polars pandas duckdb pyspark faker deltalake memory_profiler pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LquWaQEmci1j"
      },
      "outputs": [],
      "source": [
        "import polars as pl\n",
        "import pandas as pd\n",
        "import duckdb\n",
        "from pyspark.sql import SparkSession\n",
        "from faker import Faker\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import psutil\n",
        "from memory_profiler import memory_usage\n",
        "\n",
        "# Initialize Spark (Single Node)\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"BigDataLab2\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .config(\"spark.driver.memory\", \"4g\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ds5_GCNycsNi"
      },
      "outputs": [],
      "source": [
        "def generate_data(num_records=1_000_000, output_path=\"social_media_data.parquet\"):\n",
        "    fake = Faker()\n",
        "\n",
        "    print(f\"Generating {num_records} records...\")\n",
        "\n",
        "    # Generate data using numpy for speed where possible\n",
        "    data = {\n",
        "        \"post_id\": [fake.uuid4() for _ in range(num_records)],\n",
        "        \"user_id\": np.random.randint(1, 100_000, num_records),\n",
        "        \"timestamp\": pd.date_range(start=\"2023-01-01\", periods=num_records, freq=\"s\").to_numpy().astype(\"datetime64[us]\"),\n",
        "        \"likes\": np.random.randint(0, 10_000, num_records),\n",
        "        \"views\": np.random.randint(0, 1_000_000, num_records),\n",
        "        \"category\": np.random.choice([\"Tech\", \"Health\", \"Travel\", \"Food\", \"Fashion\", \"Politics\", \"Sports\"], num_records),\n",
        "        \"tags\": [np.random.choice([\"#viral\", \"#new\", \"#trending\", \"#hot\", \"#update\"], size=np.random.randint(1, 4)).tolist() for _ in range(num_records)],\n",
        "        \"location\": np.random.choice([\"USA\", \"UK\", \"DE\", \"PL\", \"FR\", \"JP\", \"BR\"], num_records),\n",
        "        \"device\": np.random.choice([\"Mobile\", \"Desktop\", \"Tablet\"], num_records),\n",
        "        \"latency\": np.random.uniform(10.0, 500.0, num_records),\n",
        "        \"error_rate\": np.random.beta(1, 10, num_records),\n",
        "        \"content\": [fake.sentence() for _ in range(min(num_records, 1000))] * (num_records // 1000 + 1)\n",
        "    }\n",
        "\n",
        "    # Trim to exact size\n",
        "    data[\"content\"] = data[\"content\"][:num_records]\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    print(\"Writing to Parquet...\")\n",
        "    df.to_parquet(output_path, engine=\"pyarrow\")\n",
        "    print(f\"Data saved to {output_path}\")\n",
        "\n",
        "# Generate 5 million records\n",
        "generate_data(num_records=5_000_000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaktE6vCfZZT"
      },
      "source": [
        "# Zadanie 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Vec0sp5edMjZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "import duckdb\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql import Window\n",
        "from memory_profiler import memory_usage\n",
        "import time\n",
        "\n",
        "# Small table for JOIN (user statistics)\n",
        "user_stats = pd.DataFrame({\n",
        "    \"user_id\": np.arange(1, 10_001),\n",
        "    \"user_rank\": np.random.randint(1, 100, 10_000)\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5lr8oU2fX2P"
      },
      "outputs": [],
      "source": [
        "df_pd = pd.read_parquet(\"social_media_data.parquet\")\n",
        "df_pl = pl.read_parquet(\"social_media_data.parquet\")\n",
        "df_spark = spark.read.parquet(\"social_media_data.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tJFuCDGfsU2"
      },
      "outputs": [],
      "source": [
        "def benchmark(func):\n",
        "    mem_before = memory_usage()[0]\n",
        "    t0 = time.time()\n",
        "\n",
        "    result = func()\n",
        "\n",
        "    t1 = time.time()\n",
        "    mem_after = memory_usage()[0]\n",
        "\n",
        "    return {\n",
        "        \"time_sec\": t1 - t0,\n",
        "        \"memory_mb\": mem_after - mem_before,\n",
        "        \"result\": result\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keLH6y2Vfx-k"
      },
      "source": [
        "## Query A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "RQdH5vX2f1Jc"
      },
      "outputs": [],
      "source": [
        "def pandas_query_A():\n",
        "    return df_pd.groupby(\"category\")[[\"likes\", \"views\"]].mean()\n",
        "\n",
        "def polars_query_A():\n",
        "    return (\n",
        "        df_pl\n",
        "        .group_by(\"category\")\n",
        "        .agg([\n",
        "            pl.col(\"likes\").mean().alias(\"mean_likes\"),\n",
        "            pl.col(\"views\").mean().alias(\"mean_views\")\n",
        "        ])\n",
        "    )\n",
        "\n",
        "def duckdb_query_A():\n",
        "    return duckdb.sql(\"\"\"\n",
        "        SELECT category, AVG(likes), AVG(views)\n",
        "        FROM 'social_media_data.parquet'\n",
        "        GROUP BY category\n",
        "    \"\"\").df()\n",
        "\n",
        "def spark_query_A():\n",
        "    return df_spark.groupBy(\"category\").agg(\n",
        "        F.avg(\"likes\"), F.avg(\"views\")\n",
        "    ).collect()\n",
        "\n",
        "print(\"Pandas A:\", benchmark(pandas_query_A))\n",
        "print(\"Polars A:\", benchmark(polars_query_A))\n",
        "print(\"DuckDB A:\", benchmark(duckdb_query_A))\n",
        "print(\"Spark A:\", benchmark(spark_query_A))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09kW9ZoPipir"
      },
      "source": [
        "Query A. Agregacja średnich wartości\n",
        "\n",
        "W ramach pierwszego zapytania przeprowadzono agregację średnich wartości liczby polubień oraz wyświetleń dla każdej kategorii postów.\n",
        "\n",
        "Wyniki:\n",
        "1. Pandas: czas wykonania ~0.54 s, przyrost pamięci ~13 MB.\n",
        "2. Polars: czas wykonania ~0.15 s, przyrost pamięci ~0.04 MB.\n",
        "3. DuckDB: czas wykonania ~0.12 s, przyrost pamięci ~2.7 MB.\n",
        "4. Spark: czas wykonania ~1.39 s, przyrost pamięci niedokładny.\n",
        "\n",
        "Najszybszym silnikiem w tym zadaniu był DuckDB, a Spark był najwolniejszy w przetwarzaniu lokalnym. Różnice w przyroście pamięci wynikają głównie ze sposobu działania bibliotek.\n",
        "Ogólnie wszystkie silniki zwróciły te same wartości średnich, co potwierdza poprawność agregacji."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeAsE8b6gB49"
      },
      "source": [
        "## Query B."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Z29RkWDKgDZ8"
      },
      "outputs": [],
      "source": [
        "def pandas_query_B():\n",
        "    return (\n",
        "        df_pd\n",
        "        .sort_values([\"category\", \"views\"], ascending=[True, False])\n",
        "        .groupby(\"category\")\n",
        "        .head(3)\n",
        "    )\n",
        "\n",
        "def polars_query_B():\n",
        "    return (\n",
        "        df_pl\n",
        "        .sort([\"category\", \"views\"], descending=[False, True])\n",
        "        .group_by(\"category\")\n",
        "        .head(3)\n",
        "    )\n",
        "\n",
        "def duckdb_query_B():\n",
        "    return duckdb.sql(\"\"\"\n",
        "        SELECT *\n",
        "        FROM (\n",
        "            SELECT *,\n",
        "                   ROW_NUMBER() OVER (PARTITION BY category ORDER BY views DESC) AS rn\n",
        "            FROM 'social_media_data.parquet'\n",
        "        )\n",
        "        WHERE rn <= 3\n",
        "    \"\"\").df()\n",
        "\n",
        "\n",
        "def spark_query_B():\n",
        "    w = Window.partitionBy(\"category\").orderBy(F.col(\"views\").desc())\n",
        "    return (\n",
        "        df_spark\n",
        "        .withColumn(\"rn\", F.row_number().over(w))\n",
        "        .filter(F.col(\"rn\") <= 3)\n",
        "        .collect()\n",
        "    )\n",
        "print(\"Pandas B:\", benchmark(pandas_query_B))\n",
        "print(\"Polars B:\", benchmark(polars_query_B))\n",
        "print(\"DuckDB B:\", benchmark(duckdb_query_B))\n",
        "print(\"Spark B:\", benchmark(spark_query_B))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MP33wwpkd9o"
      },
      "source": [
        "Query B. Top-N postów według liczby wyświetleń w każdej kategorii\n",
        "\n",
        "W ramach drugiego zapytania przeprowadzono wybór trzech postów o najwyższej liczbie wyświetleń dla każdej kategorii.\n",
        "\n",
        "Wyniki:\n",
        "1. Pandas: czas wykonania ~7.51 s, przyrost pamięci ~0 MB.\n",
        "2. Polars: czas wykonania ~7.16 s, przyrost pamięci ~1144 MB.\n",
        "3. DuckDB: czas wykonania ~17.28 s, przyrost pamięci ~170 MB.\n",
        "4. Spark: czas wykonania ~20.15 s, przyrost pamięci ~2 MB.\n",
        "\n",
        "Najszybszym silnikiem w tym zadaniu był Polars, choć przyrost pamięci był znaczący, co wynika z operacji w pamięci dla dużych zbiorów danych.\n",
        "Najwolniejszym silnikiem w przetwarzaniu lokalnym był Spark.\n",
        "\n",
        "Wszystkie silniki zwróciły te same 21 rekordów (7 kategorii × top-3 posty)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOfPE2mzgVyB"
      },
      "source": [
        "## Query C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "z3skxrxUgEqh"
      },
      "outputs": [],
      "source": [
        "def pandas_query_C():\n",
        "    df_joined = df_pd.merge(user_stats, on=\"user_id\", how=\"inner\")\n",
        "    return df_joined[df_joined[\"user_rank\"] > 50]\n",
        "\n",
        "df_pl_small = pl.from_pandas(user_stats)\n",
        "\n",
        "def polars_query_C():\n",
        "    return (\n",
        "        df_pl.join(df_pl_small, on=\"user_id\", how=\"inner\")\n",
        "             .filter(pl.col(\"user_rank\") > 50)\n",
        "    )\n",
        "\n",
        "\n",
        "def duckdb_query_C():\n",
        "    duckdb.register(\"user_stats_df\", user_stats)\n",
        "    return duckdb.sql(\"\"\"\n",
        "        SELECT *\n",
        "        FROM 'social_media_data.parquet' AS p\n",
        "        JOIN user_stats_df u USING(user_id)\n",
        "        WHERE user_rank > 50\n",
        "    \"\"\").df()\n",
        "\n",
        "df_spark_small = spark.createDataFrame(user_stats)\n",
        "\n",
        "def spark_query_C():\n",
        "    return (\n",
        "        df_spark.join(df_spark_small, \"user_id\", \"inner\")\n",
        "        .filter(F.col(\"user_rank\") > 50)\n",
        "        .collect()\n",
        "    )\n",
        "\n",
        "print(\"Pandas C:\", benchmark(pandas_query_C))\n",
        "print(\"Polars C:\", benchmark(polars_query_C))\n",
        "print(\"DuckDB C:\", benchmark(duckdb_query_C))\n",
        "print(\"Spark C:\", benchmark(spark_query_C))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query C.\n",
        "\n",
        "Wyniki uzyskane przy użyciu różnych silników:\n",
        "\n",
        "1. Pandas: czas wykonania ~1.49 s, przyrost pamięci ~0 MB.\n",
        "2. Polars: czas wykonania ~1.12 s, przyrost pamięci ~150 MB.\n",
        "3. DuckDB: czas wykonania ~3.29 s, przyrost pamięci ~130 MB.\n",
        "4. Spark: czas wykonania ~36 s, przyrost pamięci ~100 MB\n",
        "\n",
        "Najszybszym silnikiem w tym zadaniu był Polars, a Spark był najwolniejszy."
      ],
      "metadata": {
        "id": "r2LiHXEErqfu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlnWrRjKgjcd"
      },
      "source": [
        "## Scalability Test (Polars & DuckDB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYBzjpRfglJ7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import duckdb\n",
        "import polars as pl\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-883foF8hDxS",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "def time_run(func, runs=3):\n",
        "    times = []\n",
        "    for _ in range(runs):\n",
        "        start = time.time()\n",
        "        func()\n",
        "        times.append(time.time() - start)\n",
        "    return min(times)\n",
        "\n",
        "duckdb_queries = {\n",
        "    \"A\": duckdb_query_A,\n",
        "    \"B\": duckdb_query_B,\n",
        "    \"C\": duckdb_query_C\n",
        "}\n",
        "\n",
        "duckdb_threads = [1, 2, 4, 8]\n",
        "duckdb_results = []\n",
        "\n",
        "for qname, qfunc in duckdb_queries.items():\n",
        "    print(f\"\\nDuckDB — Query {qname}\")\n",
        "    for n in duckdb_threads:\n",
        "        duckdb.sql(f\"PRAGMA threads={n}\")\n",
        "        t = time_run(qfunc)\n",
        "        duckdb_results.append({\n",
        "            \"engine\": \"DuckDB\",\n",
        "            \"query\": qname,\n",
        "            \"threads\": n,\n",
        "            \"time\": t\n",
        "        })\n",
        "        print(f\"Threads={n}: {t:.4f} s\")\n",
        "\n",
        "duckdb_df = pd.DataFrame(duckdb_results)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DuckDB scalability benchmark"
      ],
      "metadata": {
        "id": "GWGx4U9o3R5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duckdb_queries = {\n",
        "    \"A\": duckdb_query_A,\n",
        "    \"B\": duckdb_query_B,\n",
        "    \"C\": duckdb_query_C\n",
        "}\n",
        "\n",
        "duckdb_threads = [1, 2, 4, 8]\n",
        "duckdb_results = []\n",
        "\n",
        "for qname, qfunc in duckdb_queries.items():\n",
        "    print(f\"\\nDuckDB — Query {qname}\")\n",
        "    for n in duckdb_threads:\n",
        "        duckdb.sql(f\"PRAGMA threads={n}\")\n",
        "        t = time_run(qfunc)\n",
        "        duckdb_results.append({\n",
        "            \"engine\": \"DuckDB\",\n",
        "            \"query\": qname,\n",
        "            \"threads\": n,\n",
        "            \"time\": t\n",
        "        })\n",
        "        print(f\"Threads={n}: {t:.4f} s\")\n",
        "\n",
        "duckdb_df = pd.DataFrame(duckdb_results)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "QCMNM6rZ3afu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Polars scalability benchmark"
      ],
      "metadata": {
        "id": "0WuOdgei3cKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import polars as pl\n",
        "import pandas as pd\n",
        "\n",
        "def time_run(func, runs=3):\n",
        "    times = []\n",
        "    for _ in range(runs):\n",
        "        start = time.time()\n",
        "        func()\n",
        "        times.append(time.time() - start)\n",
        "    return min(times)\n",
        "\n",
        "polars_results = []\n",
        "\n",
        "for n in [1, 2, 4, 8]:\n",
        "    print(f\"\\nPolars — threads={n}\")\n",
        "    os.environ[\"POLARS_MAX_THREADS\"] = str(n)\n",
        "\n",
        "    df_pl_test = pl.read_parquet(\"social_media_data.parquet\")\n",
        "    df_pl_small_test = pl.from_pandas(user_stats)\n",
        "\n",
        "    def polars_query_A_test():\n",
        "        return (\n",
        "            df_pl_test\n",
        "            .group_by(\"category\")\n",
        "            .agg([\n",
        "                pl.col(\"likes\").mean(),\n",
        "                pl.col(\"views\").mean()\n",
        "            ])\n",
        "        )\n",
        "\n",
        "    def polars_query_B_test():\n",
        "        return (\n",
        "            df_pl_test\n",
        "            .sort([\"category\", \"views\"], descending=[False, True])\n",
        "            .group_by(\"category\")\n",
        "            .head(3)\n",
        "        )\n",
        "\n",
        "    def polars_query_C_test():\n",
        "        return (\n",
        "            df_pl_test\n",
        "            .join(df_pl_small_test, on=\"user_id\", how=\"inner\")\n",
        "            .filter(pl.col(\"user_rank\") > 50)\n",
        "        )\n",
        "\n",
        "    for name, fn in zip(\n",
        "        [\"A\", \"B\", \"C\"],\n",
        "        [polars_query_A_test, polars_query_B_test, polars_query_C_test]\n",
        "    ):\n",
        "        t = time_run(fn)\n",
        "        polars_results.append({\n",
        "            \"engine\": \"Polars\",\n",
        "            \"query\": name,\n",
        "            \"threads\": n,\n",
        "            \"time\": t\n",
        "        })\n",
        "        print(f\"Query {name}: {t:.4f} s\")\n",
        "\n",
        "polars_df = pd.DataFrame(polars_results)\n",
        "polars_df\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PIdh05V73fDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combine + compute speedup"
      ],
      "metadata": {
        "id": "g5ihW1z03gbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.concat([duckdb_df, polars_df], ignore_index=True)\n",
        "\n",
        "def compute_speedup(df):\n",
        "    df = df.copy()\n",
        "    for (engine, query), g in df.groupby([\"engine\", \"query\"]):\n",
        "        base = g[g[\"threads\"] == 1][\"time\"].iloc[0]\n",
        "        df.loc[g.index, \"speedup\"] = base / g[\"time\"]\n",
        "    return df\n",
        "\n",
        "results_df = compute_speedup(results_df)\n",
        "\n",
        "for q in [\"A\", \"B\", \"C\"]:\n",
        "    plt.figure(figsize=(6,4))\n",
        "    sub = results_df[results_df[\"query\"] == q]\n",
        "    for engine in sub[\"engine\"].unique():\n",
        "        d = sub[sub[\"engine\"] == engine]\n",
        "        plt.plot(d[\"threads\"], d[\"speedup\"], marker=\"o\", label=engine)\n",
        "    plt.title(f\"Speedup — Query {q}\")\n",
        "    plt.xlabel(\"Threads\")\n",
        "    plt.ylabel(\"Speedup\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "QnQzb2WC3iiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sprawdzono jak zmiana liczby wątków wpływa na czas zapytań.\n",
        "\n",
        "![QueryA](Speedup-queryA.png)",
        "![QueryB](Speedup-queryB.png)",
        "![QueryC](Speedup-queryC.png)",
        "\n",
        "\n**DuckDB**\n",
        "\n",
        "Query A: Brak reakcji na wątki (ok 0.10 s) zapytanie jest zbyt proste\n",
        "Query B i C: Najlepiej działają przy 2 wątkach.\n",
        "DuckDB błyskawicznie się nasyca i w tym konkretnym przypadku słabo wykorzystuje dużą liczbę rdzeni.\n",
        "\n",
        "\n",
        "**Polars** poradził sobie nieco lepiej:\n",
        "\n",
        "Query A: Podobnie jak w DuckDB, prawie bez zmian (ok 0.15 s).\n",
        "Query B: Czas spadł z 6.88 s na 6.43 s przy 8 wątkach. Mały zysk, ale jest.\n",
        "Query C: Stabilnie do 4 wątków, przy 8 nastąpiło spowolnienie.\n",
        "\n",
        "\n",
        "Polars wydaje się odrobinę lepiej radzi sobie z bardziej złożonymi operacjami, podczas gdy DuckDB jest stabilny, ale mało podatny na skalowanie."
      ],
      "metadata": {
        "id": "sAlkEhSt7c83"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zadanie 3"
      ],
      "metadata": {
        "id": "J0P9AIKV9gtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "import time\n",
        "from memory_profiler import memory_usage\n",
        "\n",
        "file_path = \"social_media_data.parquet\"\n",
        "filter_expr = pl.col(\"views\") > 1000\n",
        "\n",
        "def benchmark_polars(func):\n",
        "    mem_usage = []\n",
        "    def wrapper():\n",
        "        return func()\n",
        "\n",
        "    start_time = time.time()\n",
        "    mem_usage = memory_usage((wrapper, ), max_iterations=1)\n",
        "    end_time = time.time()\n",
        "\n",
        "    result = wrapper()\n",
        "    elapsed_time = end_time - start_time\n",
        "    peak_memory = max(mem_usage) - min(mem_usage)\n",
        "\n",
        "    return {\"time_sec\": elapsed_time, \"peak_memory_MB\": peak_memory, \"rows\": len(result)}\n",
        "\n",
        "# Eager Execution\n",
        "def polars_eager():\n",
        "    df = pl.read_parquet(file_path)\n",
        "    filtered = df.filter(filter_expr)\n",
        "    return filtered\n",
        "\n",
        "# Lazy Execution\n",
        "def polars_lazy():\n",
        "    df_lazy = pl.scan_parquet(file_path)\n",
        "    filtered_lazy = df_lazy.filter(filter_expr).collect()\n",
        "    return filtered_lazy\n",
        "\n",
        "# Streaming Execution\n",
        "def polars_streaming():\n",
        "    df_lazy = pl.scan_parquet(file_path)\n",
        "    filtered_stream = df_lazy.filter(filter_expr).collect(streaming=True)\n",
        "    return filtered_stream\n",
        "\n",
        "results = []\n",
        "\n",
        "for mode, func in [(\"Eager\", polars_eager), (\"Lazy\", polars_lazy), (\"Streaming\", polars_streaming)]:\n",
        "    print(f\"Running Polars {mode} execution...\")\n",
        "    bench = benchmark_polars(func)\n",
        "    bench[\"mode\"] = mode\n",
        "    results.append(bench)\n",
        "    print(f\"{mode}: time={bench['time_sec']:.4f}s, peak_memory={bench['peak_memory_MB']:.2f} MB, rows={bench['rows']}\")\n",
        "\n",
        "import pandas as pd\n",
        "df_results = pd.DataFrame(results)[[\"mode\", \"time_sec\", \"peak_memory_MB\", \"rows\"]]\n",
        "print(\"\\nPolars Execution Modes Benchmark:\")\n",
        "print(df_results)\n"
      ],
      "metadata": {
        "id": "YBG8wjig71km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Polars Execution Modes Benchmark:\n",
        "\n",
        "```\n",
        "        mode  time_sec  peak_memory_MB     rows\n",
        "0      Eager  3.278074      386.316406  4995129\n",
        "1       Lazy  2.165080      345.730469  4995129\n",
        "2  Streaming  2.144784      331.070312  4995129\n",
        "```\n",
        "**Eager execution** wyląda najsłabiej. Próba nie tylko trwa najdłużej, ale też najbardziej obciąża komputer. Przy większych plikach szybko doprowadzi do wyczerpaniu pamięci.\n",
        "\n",
        "**Lazy execution** to dobry skok wydajności. Polars lepiej zarządza zasobami, co skróciło czas o ponad sekundę.\n",
        "\n",
        "**Streaming execution** jest najbardziej ekonomiczny pod kątem pamięci.\n",
        "\n",
        "Tryby Lazy i Streaming są szybsze i bezpieczniejsze dla systemu. Jeśli jednak zbiór danych przekroczy możliwości jednej maszyny to naturalnym krokiem będzie przejście na Apache Spark i przetwarzanie rozproszone."
      ],
      "metadata": {
        "id": "yUqeff70_jye"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o8VP-BNe_1Yw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "keLH6y2Vfx-k",
        "LeAsE8b6gB49",
        "vOfPE2mzgVyB",
        "GWGx4U9o3R5P"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
